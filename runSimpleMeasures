import embed_parse as mep
import sys
import itertools as it
import os
import numpy as np
import pandas as pd
import parse
from multiprocessing import Pool

import simpleMeasures as sm
import syntheticPoints as sp
import significanceTesting as st

def embeddingSizes():
	filesFiltered=mep.generateBrownFilesList()
	results=[]
	for i,file in enumerate(filesFiltered):
		print(file)
		embedding=mep.parseToEmbedding(file)
		print('beginning sumstats calculation')
		thisSumStats=sm.getSumStats(sm.allPairwiseDistSqrd(embedding,embedding))
		results.append(thisSumStats)
	resPD=pd.DataFrame._from_arrays(results, index=sm.sumStats._fields, columns=filesFiltered)
	print(resPD)
	resPD.to_csv('embeddingShapes.csv')
def embeddingSizesSynthetic():
	filesFiltered=list(sp.iterRandoms(int(1e3), 50))
	results=[]
	for file in filesFiltered:
		print('beginning sumstats calculation')
		thisSumStats=sm.getSumStats(sm.allPairwiseDistSqrd(file,file))
		results.append(thisSumStats)
	resPD=pd.DataFrame._from_arrays(results, index=sm.sumStats._fields, columns=list(sp.iterRandomsLabels()))
	print(resPD)
	resPD.to_csv('embeddingShapesSynthetic.csv')
def embeddingRuns():
	filesFiltered=mep.fileListNoSwap(mep.generateBrownFilesList())
	__embeddingRunOnFiles(filesFiltered,filesFiltered)

def noiseEmbeddingRuns():
	for algoFiles, label in zip(mep.breakFileListEmbedAlgo(mep.generateBrownFilesList()),('w2v_','glove_')):
		algoFilesNoSwap=mep.fileListNoSwap(algoFiles)
		otherFiles=list(set(algoFiles)-set(algoFilesNoSwap))
		print(algoFilesNoSwap)
		print(otherFiles)
		__embeddingRunOnFiles(algoFilesNoSwap,otherFiles, prefix=label)

def __embeddingRunOnFiles(filesGroupA, filesGroupB,prefix=''):
	mDistChange=np.zeros((len(filesGroupA),len(filesGroupB)))
	mDistChangeNormed=np.zeros((len(filesGroupA),len(filesGroupB)))
	closeChange= np.zeros((len(filesGroupA),len(filesGroupB)))
	closeChangeNormed= np.zeros((len(filesGroupA),len(filesGroupB)))
	importDictsA=list(map(mep.parse, filesGroupA))
	importDictsB=list(map(mep.parse, filesGroupB))

	commonFiles=set(filesGroupA).intersection(set(filesGroupB))
	cache=dict()
	for i in range(len(filesGroupA)):
		for j in range(len(filesGroupB)):
			#embeddings=imports[i][j]
			cacheKey=(filesGroupA[i],filesGroupB[j])
			if cacheKey in cache:
				mDistChange[i,j], mDistChangeNormed[i,j], closeChange[i,j], closeChangeNormed[i,j]=cache[cacheKey]
			else:
				embeddings=mep.pairDictsToPairEmbed(importDictsA[i],importDictsB[j])
				print(str(i)+','+str(j))
				e0v=embeddings[0].evect
				e1v=embeddings[1].evect
				mDistChange[i,j]=np.sqrt(sm.averageSquaredPairwiseDistanceChange(e0v, e1v))
				mDistChangeNormed[i,j]=np.sqrt(sm.averageSquaredPairwiseDistanceChange(sm.unitize(e0v), sm.unitize(e1v)))
				closeChange[i,j]=sm.closePointsChange(e0v, e1v)
				closeChangeNormed[i,j]=sm.closePointsChange(sm.unitize(e0v), sm.unitize(e1v))
				cacheKeyTranspose=(filesGroupB[j],filesGroupA[i])
				vals=(mDistChange[i,j], mDistChangeNormed[i,j], closeChange[i,j], closeChangeNormed[i,j])
				cache[cacheKey]=vals
	# print(oStab)
	print(mDistChange)
	print(mDistChangeNormed)
	print(closeChange)
	print(closeChangeNormed)
	# np.savetxt('orderStbility.csv',oStab,delimiter=', ')
	np.savetxt(prefix+'meanDistChangeEmbedding.csv',mDistChange,delimiter=', ')
	np.savetxt(prefix+'meanDistChangeEmbeddingNormed.csv',mDistChangeNormed,delimiter=', ')
	np.savetxt(prefix+'closeChangeEmbedding.csv',closeChange,delimiter=', ')
	np.savetxt(prefix+'closeChangeNormedEmbedding.csv',closeChangeNormed,delimiter=', ')

numPool=3
def __embeddingRunOnFiles_parallel(filesGroupA, filesGroupB,prefix=''):
	"""
	same as embeddingRunOnFiles except parallelized with pool over the files
	filesGroupB should be the larger group.
	"""
	mDistChange=np.zeros((len(filesGroupA),len(filesGroupB)))
	mDistChangeNormed=np.zeros((len(filesGroupA),len(filesGroupB)))
	closeChange= np.zeros((len(filesGroupA),len(filesGroupB)))
	closeChangeNormed= np.zeros((len(filesGroupA),len(filesGroupB)))
	importDictsA=list(map(mep.parse, filesGroupA))
	importDictsB=list(map(mep.parse, filesGroupB))
	runPairs=set()
	for i in range(len(filesGroupA)):
		def __parallelInnerLoopFunction(j):
			embeddings=mep.pairDictsToPairEmbed(importDictsA[i],importDictsB[j])
			print(str(i)+','+str(j))
			e0v=embeddings[0].evect
			e1v=embeddings[1].evect
			mDistChange=np.sqrt(sm.averageSquaredPairwiseDistanceChange(e0v, e1v))
			mDistChangeNormed=np.sqrt(sm.averageSquaredPairwiseDistanceChange(sm.unitize(e0v), sm.unitize(e1v)))
			closeChange=sm.closePointsChange(e0v, e1v)
			closeChangeNormed=sm.closePointsChange(sm.unitize(e0v), sm.unitize(e1v))
			return (i,j, mDistChange, mDistChangeNormed, closeChange, closeChangeNormed)
		toRun=[(file,filesGroupA[i]) not in runPairs for indx,file in enumerate(filesGroupB)]
		toRunIndxs=[i for i in range(len(toRun)) if toRun[i]]
		p=Pool(numPool)
		valsOut=p.map(__parallelInnerLoopFunction,toRunIndxs)
		for j,vals in enumerate(valsOut):
			mDistChange[i,j], mDistChangeNormed[i,j], closeChange[i,j], closeChangeNormed[i,j]=valsOut
			toRun.add((filesGroupA[i],filesGroupB[j]))
		for j,saveFile in filter(lambda e: not toRun[e[0]], enumerate(filesGroupB)):
			mDistChange[i,j]=mDistChange[j,i]
			mDistChangeNormed[i,j]=mDistChangeNormed[j,i]
			closeChange[i,j]=closeChange[j,i]
			closeChangeNormed[i,j]=closeChangeNormed[j,i]

	# print(oStab)
	print(mDistChange)
	print(mDistChangeNormed)
	print(closeChange)
	print(closeChangeNormed)
	# np.savetxt('orderStbility.csv',oStab,delimiter=', ')
	np.savetxt(prefix+'meanDistChangeEmbedding.csv',mDistChange,delimiter=', ')
	np.savetxt(prefix+'meanDistChangeEmbeddingNormed.csv',mDistChangeNormed,delimiter=', ')
	np.savetxt(prefix+'closeChangeEmbedding.csv',closeChange,delimiter=', ')
	np.savetxt(prefix+'closeChangeNormedEmbedding.csv',closeChangeNormed,delimiter=', ')
def syntheticRuns():
	shapes=list(sp.iterRandoms(int(1e3), 50))
	mDistChange=np.zeros((len(shapes),len(shapes)))
	mDistChangeNormed=np.zeros((len(shapes),len(shapes)))
	closeChange= np.zeros((len(shapes),len(shapes)))
	closeChangeNormed= np.zeros((len(shapes),len(shapes)))
	for i in range(len(shapes)):
		for j in range(i):
			print('loop:'+str(i)+', '+str(j))
			mDistChange[i,j]=np.sqrt(sm.averageSquaredPairwiseDistanceChange(shapes[i], shapes[j]))
			mDistChangeNormed[i,j]=np.sqrt(sm.averageSquaredPairwiseDistanceChange(sm.unitize(shapes[i]), sm.unitize(shapes[j])))
			closeChange[i,j]=sm.closePointsChange(shapes[i], shapes[j])
			closeChangeNormed[i,j]=sm.closePointsChange(sm.unitize(shapes[i]), sm.unitize(shapes[j]))
	mDistChange+=mDistChange.T
	mDistChangeNormed+=mDistChangeNormed.T
	closeChange+=closeChange.T
	closeChangeNormed+=closeChangeNormed.T

	#TODO: need re-replicate synthetics to then run significance testing
	#TODO: alignment of linear subspaces

	print(mDistChange)
	np.savetxt('meanDistChangeSyntheticNotAligned.csv',mDistChange,delimiter=', ')
	np.savetxt('meanDistChangeSyntheticNotAlignedNormed.csv',mDistChangeNormed,delimiter=', ')
	np.savetxt('closeChangeSyntheticNotAligned.csv',closeChange,delimiter=', ')
	np.savetxt('closeChangeNormedSyntheticNotAligned.csv',closeChangeNormed,delimiter=', ')

if __name__=="__main__":
	# embeddingSizes()
	# embeddingRuns()
	noiseEmbeddingRuns()
	# embeddingSizesSynthetic()
	# syntheticRuns()
